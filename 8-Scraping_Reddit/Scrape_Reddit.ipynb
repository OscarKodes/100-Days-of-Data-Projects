{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7df194",
   "metadata": {},
   "source": [
    "# SCRAPING REDDIT\n",
    "\n",
    "Referenced Link: https://towardsdatascience.com/scraping-reddit-data-1c0af3040768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f57b17",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# SETUP STEPS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9416b",
   "metadata": {},
   "source": [
    "## Import env for API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c9bde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6590cb",
   "metadata": {},
   "source": [
    "## Create PRAW instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc10556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id=os.getenv(\"my_client_id\"), \n",
    "                     client_secret=os.getenv(\"my_client_secret\"), \n",
    "                     user_agent=os.getenv(\"my_user_agent\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fd61e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# SCRAPING CAPABILITIES:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0387c7",
   "metadata": {},
   "source": [
    "## Scrape Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eca7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Simple Questions Thread\n",
      "[D] Machine Learning - WAYR (What Are You Reading) - Week 140\n",
      "[D] Fan-made NeurIPS 2022 Movie Trailer\n",
      "[P] What we learned by benchmarking TorchDynamo (PyTorch team), ONNX Runtime and TensorRT on transformers model (inference)\n",
      "[R] LocoProp: Enhancing BackProp via Local Loss Optimization (Google Brain, 2022)\n"
     ]
    }
   ],
   "source": [
    "# get 5 hot posts from the MachineLearning subreddit\n",
    "\n",
    "hot_posts = reddit.subreddit('MachineLearning').hot(limit=5)\n",
    "\n",
    "for post in hot_posts:\n",
    "    \n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592749c",
   "metadata": {},
   "source": [
    "## Reddit Posts into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f191b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[D] Simple Questions Thread</td>\n",
       "      <td>6</td>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>26</td>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>1.659280e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[D] Machine Learning - WAYR (What Are You Read...</td>\n",
       "      <td>95</td>\n",
       "      <td>vg5kjd</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>17</td>\n",
       "      <td>This is a place to share machine learning rese...</td>\n",
       "      <td>1.655675e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D] Fan-made NeurIPS 2022 Movie Trailer</td>\n",
       "      <td>114</td>\n",
       "      <td>wey49o</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>12</td>\n",
       "      <td>[https://twitter.com/postrat\\_dril/status/1554...</td>\n",
       "      <td>1.659505e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[P] What we learned by benchmarking TorchDynam...</td>\n",
       "      <td>45</td>\n",
       "      <td>weyup0</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>3</td>\n",
       "      <td>**TL;DR**: `TorchDynamo` (prototype from PyTor...</td>\n",
       "      <td>1.659507e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[R] LocoProp: Enhancing BackProp via Local Los...</td>\n",
       "      <td>105</td>\n",
       "      <td>weoh6w</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>8</td>\n",
       "      <td>Paper: [https://arxiv.org/abs/2106.06199](http...</td>\n",
       "      <td>1.659478e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0                        [D] Simple Questions Thread      6  wcqp3a   \n",
       "1  [D] Machine Learning - WAYR (What Are You Read...     95  vg5kjd   \n",
       "2            [D] Fan-made NeurIPS 2022 Movie Trailer    114  wey49o   \n",
       "3  [P] What we learned by benchmarking TorchDynam...     45  weyup0   \n",
       "4  [R] LocoProp: Enhancing BackProp via Local Los...    105  weoh6w   \n",
       "\n",
       "         subreddit                                                url  \\\n",
       "0  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "1  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "2  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "3  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "4  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "\n",
       "   num_comments                                               body  \\\n",
       "0            26  Please post your questions here instead of cre...   \n",
       "1            17  This is a place to share machine learning rese...   \n",
       "2            12  [https://twitter.com/postrat\\_dril/status/1554...   \n",
       "3             3  **TL;DR**: `TorchDynamo` (prototype from PyTor...   \n",
       "4             8  Paper: [https://arxiv.org/abs/2106.06199](http...   \n",
       "\n",
       "        created  \n",
       "0  1.659280e+09  \n",
       "1  1.655675e+09  \n",
       "2  1.659505e+09  \n",
       "3  1.659507e+09  \n",
       "4  1.659478e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "posts = []\n",
    "\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "for post in ml_subreddit.hot(limit=5):\n",
    "    \n",
    "    posts.append([post.title, \n",
    "                  post.score, \n",
    "                  post.id, \n",
    "                  post.subreddit, \n",
    "                  post.url, \n",
    "                  post.num_comments, \n",
    "                  post.selftext, \n",
    "                  post.created])\n",
    "    \n",
    "posts = pd.DataFrame(posts,\n",
    "                     columns=['title', \n",
    "                              'score', \n",
    "                              'id', \n",
    "                              'subreddit', \n",
    "                              'url', \n",
    "                              'num_comments', \n",
    "                              'body', \n",
    "                              'created'])\n",
    "\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654202d",
   "metadata": {},
   "source": [
    "## Checking the body of a post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c234ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\\n\\nThread will stay alive until next one so keep posting after the date in the title.\\n\\nThanks to everyone for answering questions in the previous thread!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575f1b3",
   "metadata": {},
   "source": [
    "## Get the top level comments of a post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c247519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor kid just wanted to sleep in.\n",
      "the little baby run to his momma is fucken adorable\n",
      "“Omg come quick he’s ded! oh nvm he’s just a lazy shit thanks fellas”\n",
      "I had no idea that I needed some passed out baby elephant in my life.\n",
      "That mom trusts the keepers with her baby. That's some respect\n",
      "I think every new parent can relate to looking at their baby and wanting to give them a little nudge to make sure they're still alive.\n",
      "Wait, what happened to that sprinkling water on the face, thing? I thought that would be a natural instinct for elephants.\n",
      "\n",
      "Maybe child rearing practices have changed since I was a kid.\n",
      "I have narcolepsy, the way my dad used to get me up for school was let my dog into my room. She would lick my face until I woke up then lie down next to me and sloooowly stretch out her legs pushing me out of bed. It was very effective\n",
      "Aww that cute little scramble for mama after waking up is sooo cute\n",
      "I love that there’s a full-fledge relationship between the elephant and the keepers, enough so that it can casually ask for help\n",
      "There's such intelligence there. They're closer to us cognitively than I think we're prepared for.\n",
      "This is like getting my pug out of bed\n",
      "Looks like all moms are the same. We get so worried about our babies. So sweet\n",
      "I only just now realized how big baby elephants are in comparison to us... They always looked so small to me, but they’re like the size of a large dog\n",
      "Wha- huh. Who? MOM?!?! MOM! - Baby Elephant Probably\n",
      "I've been to Prague twice and each time I had to visit the Zoo there. If you ever get a chance to visit Prague the Zoo is an absolute must. It's consistently ranked a top zoo in the world. There's plenty of animals I've never see anywhere else before, the admission is a steal, the food is awesome, and the bat exhibit scares the hell out of me. I'm cool with bats but being able to walk into their darkened enclosure and have them fly around you... did it twice and each time I hit the deck and army crawled out of there. The elephant enclosure is also really great and they had some baby elephants when I was there last a few years ago. Go visit the Prague Zoo!!\n",
      "I love this! Thanks for posting OP.\n",
      "I wish somehow we could integrate elephants into human society more. Fuck the ivory trade, make elephants our neighbors.\n",
      "why the elephant so small? the mom is almost as tall as a human.\n",
      "I’ve done that when my kid was sick, and I couldn’t tell if she was breathing. I regretted it 10 seconds later.\n",
      "That smile on his face when he gets the baby up. He loves his job\n",
      "We should change it from \"slept like a baby\" to \"slept like a baby elephant\". More accurate for what people mean when they say that.\n",
      "Awww. She probably thought something was wrong with her baby. Elephants always ask for help if something is wrong with their kid. So sweet that she cares so much!\n",
      "He's tuckered out. Let the growing boy sleep\n",
      "I need sound!\n",
      "That baby elephant is a whole mood right now\n",
      "I like how the man smiles when the elephant gets up\n",
      "Where is it asking for help?\n",
      "I like how the little calf is sleeping with its mouth slightly open and the little twitch from deep sleep dreaming.\n",
      "i love elephants, so beautiful and majestic. and that little baby elephant strolling over to his mom when he wakes up is just TOO CUTE\n",
      "My old boy (dog) sleeps like this too. He is deaf and blind, and it's hard to wake him without startling him. I usually tickle his feet fluffs and that gets him up.\n",
      "Elephants are the animals I didn't know I wanted\n",
      "Here you go be the bad guy - Mom\n",
      "*the baby elephant* me\n",
      "\n",
      "*the mom elephant* my mom\n",
      "\n",
      "*the keepers* my siblings\n",
      "Momma was worried about hers whittle baby! So sweet!\n",
      "My toddler as goes from dead asleep to running full speed in a matter of seconds\n",
      "As if there’s a single human parent who hasn’t done this (suspect that a sleeping infant is dead).\n",
      "I really have a hard time believing zoos are some sort of prison for animals. Sure, there are plenty of poorly managed zoos. But the good ones are essentially a utopia for these animals. Provided the enclosure is big enough for ample room for play and exploration, and hiding when they want to get away from the crowd, they get free meals, there are 0 predators (including poachers) and it seems like the caretakes will usually genuinely care about these animals.\n",
      "u/savethisvideo\n",
      "Was mama using her trunk to feel if the baby was breathing?\n",
      "Mom called the truant officers.\n",
      "I feel that tapping butt shaking not waking up hard core. Every day at 6 a.m. trying to wake up my kid for kindergarten.\n",
      "Elephants are one of the few species that potentially recognize family.  They live 60-80 years and have great memories so it’s always blown my mind on how they perceive grandkids.\n",
      "Now on bucket list: Wake up sleepy baby elephant.\n",
      "\"If you dont wake up right now, imma call the humans on you\"\n",
      "I mean, it really looks like she walked up tot hem and was like, “hey sorry fellahs, my trunk can’t wake this kid up, use your creeepy shrunken top feet to nudge ‘em.”\n",
      "\n",
      "Then when the kid wakes up and everyone walks away she looks like she’s saying, “really appreciate it,guys.”\n",
      "\n",
      "Fuckin elephants man, they seem to be pretty sentient to me.\n",
      "What species of elephant is this?\n",
      "\n",
      "I have a feeling they're kinda smaller than I pictured them to be\n",
      "Wholesome\n",
      "Me trying to get my dog to move over so I can try to some room on the bed at night. Especially after I preheat the bed.\n",
      "Wakey wakey time for schoo\n",
      "snore.... snore... sno-  FOOTBALL PRACTICE!\n",
      "Can understand getting anxious when baby won't wake up and you thinking something is wrong.  You want them to sleep but then prod them to make sure they're still alive.\n",
      "Well that’s the sweetest damn thing I’ve ever seen\n",
      "Man elephants are beautiful animals\n",
      "r/LikeUs\n",
      "u/vredditdownloader\n",
      "I want to be friends with an elephant so bad, it looks like such a pure and everlasting friendship.\n",
      "Watching that baby elephant run convinces me that elephants are just big humans bent over inside silly costumes\n",
      "Me after consecutive 10 hour shifts\n",
      "Me pretending to sleep with my DS under my pillow\n",
      "I love how comfortable she is with them around her layabout baby.\n",
      "When she looks at the keeper she has that \"can you believe this shit?\" face. So cute.\n",
      "I was so scared before I read the title when I saw the first few moments.  Then I loved it.\n",
      "Overacting to a her kid being asleep !! Yep she's definitely a mom\n",
      "What a great job... i am so jealous.\n",
      "“Moooom five more minutes.” \n",
      "\n",
      "“Not in five minutes, now!” \n",
      "\n",
      "“I can’t hear you, I’m sleeping.”\n",
      "\n",
      "“Alright, I’m getting the humans.” \n",
      "\n",
      "“No wait I’ll get up!”\n",
      "I now need an elephant in my life and not a girlfriend\n",
      "[removed]\n",
      "Kid was up all night on that damn xbox again.\n",
      "How exactly is the mother calling for help? Am I missing something?\n",
      "Elephants are so connected. I waver between deep empathy & deep pain when I see scenes like this, because of the way many humans have treated elephants (and yet elephants still trust us). They’re such incredible creatures that deserve our trust and protection.\n",
      "Dogs would know how to wake our puppies\n",
      "That was me, the day after Turkey Day.\n",
      "Wish my kid would sleep that hard...\n",
      "Mine farts and wakes in a panic.\n",
      "Five more minutes, Ma.\n",
      "Moms be mommin.\n",
      "\n",
      "Maybe the keepers should strap a mirror to her foot.\n",
      "She’s like he’s over here, follow me\n",
      "\"I've tried nothing, and I'm all out of ideas.  Help!\"\n"
     ]
    }
   ],
   "source": [
    "from praw.models import MoreComments\n",
    "\n",
    "submission = reddit.submission(id=\"jh8kou\")\n",
    "\n",
    "for top_level_comment in submission.comments:\n",
    "    \n",
    "    if isinstance(top_level_comment, MoreComments):\n",
    "        \n",
    "        continue\n",
    "        \n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38372e55",
   "metadata": {},
   "source": [
    "## Turn the top comments on a post into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902ef72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poor kid just wanted to sleep in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the little baby run to his momma is fucken ado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Omg come quick he’s ded! oh nvm he’s just a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had no idea that I needed some passed out ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That mom trusts the keepers with her baby. Tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0                  Poor kid just wanted to sleep in.\n",
       "1  the little baby run to his momma is fucken ado...\n",
       "2  “Omg come quick he’s ded! oh nvm he’s just a l...\n",
       "3  I had no idea that I needed some passed out ba...\n",
       "4  That mom trusts the keepers with her baby. Tha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "\n",
    "comments = []\n",
    "\n",
    "submission = reddit.submission(id=\"jh8kou\")\n",
    "\n",
    "for comment in submission.comments:\n",
    "    \n",
    "    if isinstance(comment, MoreComments):\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    comments.append([comment.body])\n",
    "    \n",
    "comments = pd.DataFrame(comments,\n",
    "                     columns=['body'])\n",
    "\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732eb53c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "# CREATE TWO DATA FRAMES\n",
    "\n",
    "- ## Hot Posts dataframe\n",
    "- ## Top Comments from Hot Posts dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72237a9b",
   "metadata": {},
   "source": [
    "### Create top posts dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2550345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 posts scraped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[D] Simple Questions Thread</td>\n",
       "      <td>5</td>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>26</td>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>1.659280e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[D] Machine Learning - WAYR (What Are You Read...</td>\n",
       "      <td>94</td>\n",
       "      <td>vg5kjd</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>17</td>\n",
       "      <td>This is a place to share machine learning rese...</td>\n",
       "      <td>1.655675e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D] Fan-made NeurIPS 2022 Movie Trailer</td>\n",
       "      <td>115</td>\n",
       "      <td>wey49o</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>13</td>\n",
       "      <td>[https://twitter.com/postrat\\_dril/status/1554...</td>\n",
       "      <td>1.659505e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[P] What we learned by benchmarking TorchDynam...</td>\n",
       "      <td>47</td>\n",
       "      <td>weyup0</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>3</td>\n",
       "      <td>**TL;DR**: `TorchDynamo` (prototype from PyTor...</td>\n",
       "      <td>1.659507e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[R] LocoProp: Enhancing BackProp via Local Los...</td>\n",
       "      <td>106</td>\n",
       "      <td>weoh6w</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>8</td>\n",
       "      <td>Paper: [https://arxiv.org/abs/2106.06199](http...</td>\n",
       "      <td>1.659478e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0                        [D] Simple Questions Thread      5  wcqp3a   \n",
       "1  [D] Machine Learning - WAYR (What Are You Read...     94  vg5kjd   \n",
       "2            [D] Fan-made NeurIPS 2022 Movie Trailer    115  wey49o   \n",
       "3  [P] What we learned by benchmarking TorchDynam...     47  weyup0   \n",
       "4  [R] LocoProp: Enhancing BackProp via Local Los...    106  weoh6w   \n",
       "\n",
       "         subreddit                                                url  \\\n",
       "0  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "1  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "2  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "3  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "4  MachineLearning  https://www.reddit.com/r/MachineLearning/comme...   \n",
       "\n",
       "   num_comments                                               body  \\\n",
       "0            26  Please post your questions here instead of cre...   \n",
       "1            17  This is a place to share machine learning rese...   \n",
       "2            13  [https://twitter.com/postrat\\_dril/status/1554...   \n",
       "3             3  **TL;DR**: `TorchDynamo` (prototype from PyTor...   \n",
       "4             8  Paper: [https://arxiv.org/abs/2106.06199](http...   \n",
       "\n",
       "        created  \n",
       "0  1.659280e+09  \n",
       "1  1.655675e+09  \n",
       "2  1.659505e+09  \n",
       "3  1.659507e+09  \n",
       "4  1.659478e+09  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "\n",
    "\n",
    "# create empty list to gather raw post data\n",
    "posts = []\n",
    "\n",
    "# create instance of PRAW for subreddit\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "# loop through PRAW instance and record in post list\n",
    "for post in ml_subreddit.hot(limit=10):\n",
    "# for post in ml_subreddit.hot(limit=None):\n",
    "    \n",
    "    posts.append([post.title, \n",
    "                  post.score, \n",
    "                  post.id, \n",
    "                  post.subreddit, \n",
    "                  post.url, \n",
    "                  post.num_comments, \n",
    "                  post.selftext, \n",
    "                  post.created])\n",
    "\n",
    "# create dataframe for posts\n",
    "posts = pd.DataFrame(posts,\n",
    "                     columns=['title', \n",
    "                              'score', \n",
    "                              'id', \n",
    "                              'subreddit', \n",
    "                              'url', \n",
    "                              'num_comments', \n",
    "                              'body', \n",
    "                              'created'])\n",
    "\n",
    "print(len(posts), \"posts scraped.\")\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d197609",
   "metadata": {},
   "source": [
    "### Create comments dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bd7f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 top comments scraped.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   post_id  49 non-null     object\n",
      " 1   body     49 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>Hey all! Question. Are outstanding reviewer aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>We use fasstext (https://fasttext.cc/docs/en/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>What do you think how our models of the future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>If I want to train a generic image classifier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wcqp3a</td>\n",
       "      <td>What is the most profitable machine or deep le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                               body\n",
       "0  wcqp3a  Hey all! Question. Are outstanding reviewer aw...\n",
       "1  wcqp3a  We use fasstext (https://fasttext.cc/docs/en/s...\n",
       "2  wcqp3a  What do you think how our models of the future...\n",
       "3  wcqp3a  If I want to train a generic image classifier ...\n",
       "4  wcqp3a  What is the most profitable machine or deep le..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe for comments\n",
    "comments_df = pd.DataFrame(columns=['post_id', 'body'])\n",
    "\n",
    "\n",
    "# loop through ids in posts, and gather all the top comments into dataframe\n",
    "for post_id in posts.id:\n",
    "    \n",
    "    comments = []\n",
    "\n",
    "    submission = reddit.submission(id=post_id)\n",
    "\n",
    "    for comment in submission.comments:\n",
    "\n",
    "        if isinstance(comment, MoreComments):\n",
    "\n",
    "            continue\n",
    "\n",
    "        comments.append([post_id, comment.body])\n",
    "\n",
    "    comments = pd.DataFrame(comments,\n",
    "                         columns=['post_id', 'body'])\n",
    "    \n",
    "    comments_df = pd.concat([comments_df, comments], sort=False)\n",
    "\n",
    "    \n",
    "print(comments_df.shape[0], \"top comments scraped.\\n\")\n",
    "\n",
    "print(comments_df.info())\n",
    "\n",
    "comments_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
