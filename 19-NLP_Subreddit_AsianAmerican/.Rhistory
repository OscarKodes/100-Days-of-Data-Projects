MARGIN=1,
FUN=which.max)]
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
# "document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topic")
head(analyze)
unique(analyze$max_topic)
analyze <- select(merged,
"document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topic")
head(analyze)
unique(analyze$max_topic)
lda_document$max_topic <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=which.max)]
lda_document$max_topic <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=which.max)]
unique(lda_document)
unique(lda_document$max_topic)
lda_document$max_topic <-
colnames(lda_document[1:5])[apply(X=lda_document,
MARGIN=1,
FUN=which.max)]
unique(lda_document$max_topic)
lda_document$max_topic <-
colnames(lda_document)[apply(X=lda_document,
MARGIN=1,
FUN=which.max)]
unique(lda_document$max_topic)
# As opposed to one topic column
# NOTE: gamma values are to fill in the new columns
lda_document <- spread(lda_document_topics,
topic, # the col to spread
gamma) # fill in the new cols with gamma
dim(lda_document)
head(lda_document)
head(lda_document[2:5])
lda_document$max_topic <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=which.max)]
unique(lda_document$max_topic)
?which.max()
lda_document <- spread(lda_document_topics,
topic, # the col to spread
gamma) # fill in the new cols with gamma
dim(lda_document)
head(lda_document)
head(lda_document[2:5])
# Best Topic Match ----------------------------------
# create column for the topic that has the
# greatest contribution to that document
which_above <- function(row) {
values_above = c()
for (n in row) {
if (n > 0.3) {
values_above = c(values_above, n)
}
}
return (values_above)
}
lda_document$max_topics <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=which_above)]
unique(lda_document$max_topics)
lda_document$max_topics <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=which_above)]
unique(lda_document$max_topics)
unique(lda_document$max_topics)
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (values_above)
}
testing <- c(1,3,4)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (values_above)
}
testing <- c(1,3,4,5)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(1,3,4,5)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:5) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(1,3,4,5)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(1,3,5,4)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(5,3,9,4)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(9,3,1,4)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
testing <- c(5,3,1,9)
print(my_max(testing))
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
lda_document$max_topics <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=my_max)]
unique(lda_document$max_topics)
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topic")
head(analyze)
unique(analyze$max_topic)
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topic)
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 1:4) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column + 1)
}
lda_document$max_topics <-
colnames(lda_document[2:5])[apply(X=lda_document,
MARGIN=1,
FUN=my_max)]
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"2-culture"="1",
"3-racsm_v_chinese"="2",
"4-movies"="3",
"5-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 2:5) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
lda_document$max_topics <-
colnames(lda_document)[apply(X=lda_document,
MARGIN=1,
FUN=my_max)]
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"2-culture"="1",
"3-racsm_v_chinese"="2",
"4-movies"="3",
"5-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
# Ex: topic1, topic2, topic3
# As opposed to one topic column
# NOTE: gamma values are to fill in the new columns
lda_document <- spread(lda_document_topics,
topic, # the col to spread
gamma) # fill in the new cols with gamma
dim(lda_document)
head(lda_document)
head(lda_document[2:5])
# Best Topic Match ----------------------------------
# create column for the topic that has the
# greatest contribution to that document
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 2:5) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
lda_document$max_topics <-
colnames(lda_document)[apply(X=lda_document,
MARGIN=1,
FUN=my_max)]
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"2-culture"="1",
"3-racsm_v_chinese"="2",
"4-movies"="3",
"5-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
# GAMMA -------------
# How much does each topic contribute to each document?
# --> Use GAMMA statistic
# (As opposed to how much each word contributes
# to each topic, which is beta)
lda_document_topics <- tidy(lda,
matrix="gamma")
head(lda_document_topics)
tail(lda_document_topics)
# write.csv(lda_document_topics,
#           file = paste("(new)topic_gamma_match",
#                        k,
#                        ".csv",
#                        sep = ""))
# same as nrow() and ncol()
dim(lda_document_topics)
# Have each topic as a different column --------------
# Ex: topic1, topic2, topic3
# As opposed to one topic column
# NOTE: gamma values are to fill in the new columns
lda_document <- spread(lda_document_topics,
topic, # the col to spread
gamma) # fill in the new cols with gamma
dim(lda_document)
head(lda_document)
head(lda_document[2:5])
# Best Topic Match ----------------------------------
# create column for the topic that has the
# greatest contribution to that document
my_max <- function(row) {
top_value = 0
top_column = 0
for (i in 2:5) {
if (row[i] > top_value) {
top_column = i
top_value = row[i]
}
}
return (top_column)
}
lda_document$max_topics <-
colnames(lda_document)[apply(X=lda_document,
MARGIN=1,
FUN=my_max)]
# join tables together --------------------------------
dt1 <- data.table(lda_document,
key = "document")
dt2 <- data.table(df,
key = "doc_id")
merged <- dt1[dt2]
dim(merged)
colnames(merged)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"2-culture"="1",
"3-racsm_v_chinese"="2",
"4-movies"="3",
"5-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
# select only the columns you want to work with
analyze <- select(merged,
"document",
"1-culture"="1",
"2-racsm_v_chinese"="2",
"3-movies"="3",
"4-racsm_in_time"="4",
"max_topics")
head(analyze)
unique(analyze$max_topics)
head(analyze, n = 10)
#to create and work with corpora
library(tm)
#for LDA topic models
library(topicmodels)
# other useful packages
library(tidyverse)
library(tidytext)
library(stringr)
# dplyr must be placed below data.table
library(data.table)
library(dplyr)
# for sentiments
library(topicmodels)
sentiments
# textdata and nrc may need package installations
library("textdata")
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
# convert csv data into a format
# the tidyverse library can work with
colnames(df)
tidy_prompts <- df %>%
ungroup() %>%
unnest_tokens(word, text)
# from the conversion above,
# we have a new column called "word"
summary(tidy_prompts)
head(tidy_prompts)
colnames(tidy_prompts)
# Get all the "joy" sentiment words
# from the nrc dictionary
nrc_sent <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
# --> Which words do top writing prompts express joy with -------------
# inner join nrc_sent with prompts
joy_words <- tidy_prompts %>%
inner_join(nrc_sent) %>%
dplyr::count(word, sort = TRUE) # important to specify dplyer's count
# --> Which words does /r/AsianAmerican express joy with -------------
# inner join nrc_sent with prompts
joy_words <- tidy_prompts %>%
inner_join(nrc_sent) %>%
dplyr::count(word, sort = TRUE) # important to specify dplyer's count
joy_words
ggplot(prompts_sentiment, aes(negative, positive)) +
geom_point(show.legend = FALSE,
size = 15,
shape = "square",
alpha = 0.1)
prompts_sentiment <- tidy_prompts %>%
inner_join(get_sentiments("bing")) %>%
dplyr::count(doc_id, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
head(prompts_sentiment)
ggplot(prompts_sentiment, aes(negative, positive)) +
geom_point(show.legend = FALSE,
size = 15,
shape = "square",
alpha = 0.1)
# the mean sentiment analysis of all bowie lyrics together ---------
all_prompts_sentiment <- mean(prompts_sentiment$sentiment)
all_prompts_sentiment
