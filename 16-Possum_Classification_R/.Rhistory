sample <- sample.split(data$skull_width_mm, SplitRatio = 0.7)
# 70% of the data will be used to train the model
trainingData <- subset(data, sample == T)
# 30% of the data will be used to test the model
testData <- subset(data, sample == F)
###########################################
# CHECK TRAINING DATA
head(trainingData)
tail(trainingData)
str(trainingData)
summary(trainingData)
###########################################
# CHECK FOR MISSING VALUES
any(is.na(trainingData))
# Amelia package for visualizing missing data
library(Amelia)
missmap(trainingData,
main = "Missing Map",
col = c("red", "black"),
legend = T)
# Only one case in the training set with missing values, Remove it
trainingData <- na.omit(trainingData)
any(is.na(trainingData))
# Every change we make to the training data,
# we must do to the test data
testData <- na.omit(testData)
###########################################
# PREPARE THE DATA FOR MACHINE LEARNING
# One-Hot Encode Categorical Features
# NOTE: With R, one hot encoding might not be necessary
# Feature Scale Continuous Variables - Standardization
scale_numeric_cols <- function(df) {
numeric_cols <- select(df,
-id,
-site_trapped,
-sex,
-population_name)
scaled_cols <- scale(numeric_cols)
categorical_cols <- select(df,
id,
site_trapped,
sex,
population_name)
return (cbind(categorical_cols, scaled_cols))
}
trainingData <- scale_numeric_cols(trainingData)
testData <- scale_numeric_cols(testData)
#####################################################
# COMPARE REGRESSION MODELS
# full model with all variables
fullModel <- lm(skull_width_mm ~ ., data = trainingData)
summary(fullModel)
scale_numeric_cols <- function(df) {
numeric_cols <- select(df,
-id,
-site_trapped,
-sex,
-is_victoria_population)
scaled_cols <- scale(numeric_cols)
categorical_cols <- select(df,
id,
site_trapped,
sex,
is_victoria_population)
return (cbind(categorical_cols, scaled_cols))
}
trainingData <- scale_numeric_cols(trainingData)
testData <- scale_numeric_cols(testData)
#####################################################
# COMPARE REGRESSION MODELS
# full model with all variables
fullModel <- lm(skull_width_mm ~ ., data = trainingData)
summary(fullModel)
# Feature Scale Continuous Variables - Standardization
scale_numeric_cols <- function(df) {
numeric_cols <- select(df,
-id,
-site_trapped,
-sex)
scaled_cols <- scale(numeric_cols)
categorical_cols <- select(df,
id,
site_trapped,
sex)
return (cbind(categorical_cols, scaled_cols))
}
trainingData <- scale_numeric_cols(trainingData)
testData <- scale_numeric_cols(testData)
#####################################################
# COMPARE REGRESSION MODELS
# full model with all variables
fullModel <- lm(skull_width_mm ~ ., data = trainingData)
summary(fullModel)
# useful package for everything
library(tidyverse)
# Clear R's memory.
rm(list=ls())
# Set working directory
setwd("C:/Users/Oscar Ko/Desktop/100-Days-of-Data-Projects/15-Simple_ML_with_R")
# Check current working directory
getwd()
###################################################
# IMPORT DATA
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("possum.csv")
###################################################
# CHECK THE DATA
# check number of rows and columns
nrow(data)
ncol(data)
# check column names
colnames(data)
###########################################
# RENAME COLUMNS
colnames(data) <- c("id",
"site_trapped",
"population_name",
"sex",
"age",
"head_length_mm",
"skull_width_mm",
"total_length_cm",
"tail_length_cm",
"foot_length_mm",
"earconch_length_mm",
"eye_width_mm",
"chest_girth_cm",
"belly_girth_cm")
data$population_name <- NULL
# convert to categorical factors
data$site_trapped <- factor(data$site_trapped)
###########################################
# TRAIN-TEST SPLIT
library(caTools)
set.seed(42)
# Split up sample (training and test data)
sample <- sample.split(data$skull_width_mm, SplitRatio = 0.7)
# 70% of the data will be used to train the model
trainingData <- subset(data, sample == T)
# 30% of the data will be used to test the model
testData <- subset(data, sample == F)
###########################################
# CHECK TRAINING DATA
head(trainingData)
tail(trainingData)
str(trainingData)
summary(trainingData)
###########################################
# CHECK FOR MISSING VALUES
any(is.na(trainingData))
# Amelia package for visualizing missing data
library(Amelia)
missmap(trainingData,
main = "Missing Map",
col = c("red", "black"),
legend = T)
# Only one case in the training set with missing values, Remove it
trainingData <- na.omit(trainingData)
any(is.na(trainingData))
# Every change we make to the training data,
# we must do to the test data
testData <- na.omit(testData)
might not be necessary
# Feature Scale Continuous Variables - Standardization
scale_numeric_cols <- function(df) {
numeric_cols <- select(df,
-id,
-site_trapped,
-sex)
scaled_cols <- scale(numeric_cols)
categorical_cols <- select(df,
id,
site_trapped,
sex)
return (cbind(categorical_cols, scaled_cols))
}
trainingData <- scale_numeric_cols(trainingData)
testData <- scale_numeric_cols(testData)
#####################################################
# COMPARE REGRESSION MODELS
# full model with all variables
fullModel <- lm(skull_width_mm ~ ., data = trainingData)
summary(fullModel)
model2 <- lm(skull_width_mm ~ chest_girth_cm, data = trainingData)
summary(model2)
summary(fullModel)
backwards2 <- lm(skull_width_mm ~ chest_girth_cm + eye_width_mm,
data = trainingData)
summary(backwards2)
library(glmnet)
install.packages("glmnet")
library(glmnet)
# fit ridge regression model
ridge_model <- glmnet(x, y, alpha = 0)
head(trainingData[-skull_width_mm])
colnames(trainingData)
# fit ridge regression model
ridge_model <- glmnet(x = trainingData[-6],
y = trainingData$skull_width_mm,
alpha = 0)
summary(ridge_model)
# fit ridge regression model
ridge_model <- lm.ridge(skull_width_mm ~ .,
data = trainingData)
library(glmnet)
# fit ridge regression model
ridge_model <- glmnet(x = trainingData[-6],
y = trainingData$skull_width_mm,
alpha = 0)
summary(ridge_model)
# perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x = trainingData[-6],
y = trainingData$skull_width_mm,
alpha = 0)
# find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#produce plot of test MSE by lambda value
plot(cv_model)
summary(ridge_model)
# perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x = trainingData[-6],
y = trainingData$skull_width_mm,
alpha = 0)
# Full Model ----
fullModel <- lm(skull_width_mm ~ ,
data = trainingData)
summary(fullModel)
# Note: R-squared is 0.7195. Overall P-value is below 0.05.
# Backwards Elimination 1 ----  alpha = 0.05
backwards1 <- lm(skull_width_mm ~ chest_girth_cm, data = trainingData)
summary(backwards1)
# Note: R-squared is 0.4023. Overall P-value is below 0.05.
# Note: Removing the other features decreased predictive power by a lot
# Try backwards elimination with alpha level of 0.10
# Backwards Elimination 2 ---- alpha = 0.10
backwards2 <- lm(skull_width_mm ~ chest_girth_cm + eye_width_mm,
data = trainingData)
summary(backwards2)
# Note: R-squared is 0.4506. Overall P-value is below 0.05.
# Note: By increasing alpha, we allowed for eye_width_mm to stay in the model.
# this increased predictive power by about 5%.
full_model_predictions <- predict(fullModel, testData)
backwards1_predictions <- predict(backwards1, testData)
backwards2_predictions <- predict(backwards2, testData)
# side by side to compare
results_full <- cbind(full_model_predictions, testData$skull_width_mm)
results_back1 <- cbind(backwards1_predictions, testData$skull_width_mm)
results_back2 <- cbind(backwards2_predictions, testData$skull_width_mm)
colnames(results_full) <- c("predicted", "actual")
colnames(results_back1) <- c("predicted", "actual")
colnames(results_back2) <- c("predicted", "actual")
results_full <- as.data.frame(results_full)
results_back1 <- as.data.frame(results_back1)
results_back2 <- as.data.frame(results_back2)
head(results_full)
head(results_back1)
head(results_back2)
res <- residuals(fullModel)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="blue",
alpha=0.5,
bins=50)
# (We can use plot to see quick viz's of regression models)
plot(fullModel)
# Visualize full model residuals ---------------
res <- residuals(fullModel)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="blue",
alpha=0.5,
bins=50)
# Visualize backwards model 1 residuals -----------------
res <- residuals(backwards1)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="blue",
alpha=0.5,
bins=50)
# Visualize backwards model 2 residuals -----------------
res <- residuals(backwards2)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="blue",
alpha=0.5,
bins=50)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="red",
alpha=0.5,
bins=50)
res <- residuals(backwards2)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="green",
alpha=0.5,
bins=50)
res <- residuals(fullModel)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="red",
alpha=0.5,
bins=50)
res <- residuals(backwards2)
head(res)
# change to dataframe to visualize
res <- as.data.frame(res)
res
# visualize residuals
ggplot(res, aes(res)) +
geom_histogram(fill="green",
alpha=0.5,
bins=50)
assification.
###################################################
# SETUP
# useful package for everything
library(tidyverse)
# Clear R's memory.
rm(list=ls())
# Set working directory
setwd("C:/Users/Oscar Ko/Desktop/100-Days-of-Data-Projects/15-Simple_ML_with_R")
# Check current working directory
getwd()
###################################################
# IMPORT DATA
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("possum.csv")
###################################################
# CHECK THE DATA
# check number of rows and columns
nrow(data)
ncol(data)
# check column names
colnames(data)
###########################################
# RENAME COLUMNS
colnames(data) <- c("id",
"site_trapped",
"population_name",
"sex",
"age",
"head_length_mm",
"skull_width_mm",
"total_length_cm",
"tail_length_cm",
"foot_length_mm",
"earconch_length_mm",
"eye_width_mm",
"chest_girth_cm",
"belly_girth_cm")
data$population_name <- NULL
# convert to categorical factors
data$site_trapped <- factor(data$site_trapped)
###########################################
# TRAIN-TEST SPLIT
library(caTools)
set.seed(42)
# Split up sample (training and test data)
sample <- sample.split(data$skull_width_mm, SplitRatio = 0.7)
# 70% of the data will be used to train the model
trainingData <- subset(data, sample == T)
# 30% of the data will be used to test the model
testData <- subset(data, sample == F)
###########################################
# CHECK TRAINING DATA
head(trainingData)
tail(trainingData)
str(trainingData)
summary(trainingData)
###########################################
# CHECK FOR MISSING VALUES
any(is.na(trainingData))
# Amelia package for visualizing missing data
library(Amelia)
missmap(trainingData,
main = "Missing Map",
col = c("red", "black"),
legend = T)
# Only one case in the training set with missing values, Remove it
trainingData <- na.omit(trainingData)
any(is.na(trainingData))
# Every change we make to the training data,
# we must do to the test data
testData <- na.omit(testData)
###########################################
# PREPARE THE DATA FOR MACHINE LEARNING
# One-Hot Encode Categorical Features
# NOTE: With R, one hot encoding might not be necessary
# Feature Scale Continuous Variables - Standardization
scale_numeric_cols <- function(df) {
numeric_cols <- select(df,
-id,
-site_trapped,
-sex)
scaled_cols <- scale(numeric_cols)
categorical_cols <- select(df,
id,
site_trapped,
sex)
return (cbind(categorical_cols, scaled_cols))
}
trainingData <- scale_numeric_cols(trainingData)
testData <- scale_numeric_cols(testData)
logistic_model <- glm(sex ~ .,
family = binomial(link = "logit"),
data = trainingData)
summary(logistic_model)
logistic_model <- glm(sex ~ .,
family = binomial(link = "logit"),
data = trainingData)
# Logistic Regression ----------------------------
trainingData$sex
trainingData$sex <- ifelse(trainingData$sex == "m", 0, 1)
testData$sex <- ifelse(testData$sex == "m", 0, 1)
logistic_model <- glm(sex ~ .,
family = binomial(link = "logit"),
data = trainingData)
summary(logistic_model)
logistic_model2 <- glm(sex ~ head_length_mm + total_length_cm,
family = binomial(link = "logit"),
data = trainingData)
summary(logistic_model)
summary(logistic_model2)
logistic_model2 <- glm(sex ~ head_length_mm + total_length_cm,
family = binomial(link = "logit"),
data = trainingData)
summary(logistic_model)
outcome_odds_ratio <- predict(logistic_model,
testData,
type = "response")
predicted_results <- ifelse(outcome_odds_ratio > 0.5, 1, 0)
prediction_accuracy <- mean(predicted_results == testData$sex)
prediction_accuracy
# CONFUSION MATRIX (Actual data vs Predicted data)
table(testData$sex, predicted_results)
outcome_odds_ratio <- predict(logistic_model2,
testData,
type = "response")
predicted_results <- ifelse(outcome_odds_ratio > 0.5, 1, 0)
prediction_accuracy <- mean(predicted_results == testData$sex)
prediction_accuracy
# CONFUSION MATRIX (Actual data vs Predicted data)
table(testData$sex, predicted_results)
# ACCURACY for Full Logistic Regression Model = 0.53
colnames(trainingData)
colnames(trainingData[[-1]])
colnames(trainingData[-1)
colnames(trainingData[-1])
colnames(trainingData[-1, -2])
colnames(trainingData[-"sex"])
predicted_outcomes <- knn(trainingData[-3], # training data w/o labels
testData[-3],  # test data w/o labels
trainingData, # training data /w labels
k=1)
library(class)
predicted_outcomes <- knn(trainingData[-3], # training data w/o labels
testData[-3],  # test data w/o labels
trainingData, # training data /w labels
k=1)
?knn
predicted_outcomes <- knn(train=trainingData[-3], # training data w/o labels
test=testData[-3],  # test data w/o labels
cl=trainingData[3], # training data /w labels
k=1)
predicted_outcomes <- knn(train=trainingData[-3], # training data w/o labels
test=testData[-3],  # test data w/o labels
cl=trainingData, # training data /w labels
k=1)
predicted_outcomes <- knn(train=trainingData[, -3], # training data w/o labels
test=testData[, 3],  # test data w/o labels
cl=trainingData[, 3], # training data /w labels
k=1)
head(trainingData[-3])
head(trainingData[, -3])
predicted_outcomes <- knn(train=trainingData[, -3], # training data w/o labels
test=testData[, -3],  # test data w/o labels
cl=trainingData[, 3], # training data /w labels
k=1)
head(predicted_outcomes)
prediction_error <- mean(predicted_outcomes != test_outcomes)
prediction_error
