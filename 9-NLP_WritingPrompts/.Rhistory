formula_with_all
predicted_values <- predict.nn(neural_model,
test[1:13])
?compute
################################################
# MACHINE LEARNING - Neural Networks
# libraries
library(MASS) # the data set we'll use
# Clear Everything
rm(list = ls())
# Get data
data <- Boston
# check data set for any na values
any(is.na(data))
#########################################
# Standardize / Normalize the Data Units
maxs <- apply(data, 2, max)
maxs
mins <- apply(data, 2, min)
mins
scaled_data <-
scale(data,
center = mins, # each value will have min subtracted from it
scale = maxs-mins)
scaled <- as.data.frame(scaled_data)
########################################
# Split test and train sets
library(caTools)
split <- sample.split(scaled$medv, SplitRatio = 0.7)
train <- subset(scaled, split == T)
test <- subset(scaled, split == F)
#######################################
# BUILD NEURAL NET MODEL
library(neuralnet)
allCols <- paste(colnames(train), collapse = " + ")
string_formula <- paste("medv ~ ", allCols)
formula_with_all <- as.formula(string_formula)
nn <- neuralnet(formula_with_all,
data = train,
hidden = c(5, 3), # hidden neuron layers
linear.output = T)
plot(nn)
#######################################
# PREDICTIONS
predicted_values <- predict(nn,
test[1:13])
#######################################
# PREDICTIONS
?predict()
#######################################
# PREDICTIONS
?prediction()
predicted_values <- prediction(nn,
test[1:13])
predicted_values <- prediction(nn,
test[1:13])
#######################################
# PREDICTIONS
?compute()
predicted_values <- predict.nn(nn,
test[1:13])
predicted_values <- neuralnet::predict.nn(nn,
test[1:13])
predicted_values <- compute(nn,
test[1:13])
#######################################
# PREDICTIONS
?compute()
predicted_values <- neuralnet::predict(nn,
test[1:13])
predicted_values <- predict(nn,
test[1:13])
nn$weights
string_formula
allCols <- paste(colnames(train)[1:13], collapse = " + ")
string_formula <- paste("medv ~ ", allCols)
string_formula
formula_with_all <- as.formula(string_formula)
nn <- neuralnet(formula_with_all,
data = train,
hidden = c(5, 3), # hidden neuron layers
linear.output = T)
predicted_values <- predict(nn,
test[1:13])
str(predicted_values)
true_predictions <- predicted_values$net.result *
(max(data$medv)-min(data$medv)) + min(data$medv)
colnameS(predicted_values)
colnames(predicted_values)
head(predicted_values)
predicted_values <- compute(nn,
test[1:13])
head(predicted_values)
head(predicted_values)
str(predicted_values)
true_predictions <- predicted_values$net.result *
(max(data$medv)-min(data$medv)) + min(data$medv)
# Convert the test data
test_r <- (test$medv) *
(max(data$medv)-min(data$medv)) + min(data$medv)
MSE_nn <- sum((test_r = true_predictions)^2) / nrow(test)
MSE_nn
error_df <- data.frame(test_r,
true_predictions)
head(error_df)
# Visualize Error
library(tidyverse)
ggplot(error_df,
aes(x = test_r,
y = true_predictions)) +
stat_smooth()
# libraries
library(MASS) # the data set we'll use
# Clear Everything
rm(list = ls())
# Get data
data <- Boston
# check data set for any na values
any(is.na(data))
#########################################
# Standardize / Normalize the Data Units
maxs <- apply(data, 2, max)
maxs
mins <- apply(data, 2, min)
mins
scaled_data <-
scale(data,
center = mins, # each value will have min subtracted from it
scale = maxs-mins)
scaled <- as.data.frame(scaled_data)
########################################
# Split test and train sets
library(caTools)
split <- sample.split(scaled$medv, SplitRatio = 0.7)
head(split)
train <- subset(scaled, split == T)
test <- subset(scaled, split == F)
library(neuralnet)
allCols <- paste(colnames(train)[1:13], collapse = " + ")
string_formula <- paste("medv ~ ", allCols)
string_formula
formula_with_all <- as.formula(string_formula)
# neural net model
nn <- neuralnet(formula_with_all,
data = train,
hidden = c(5, 3), # hidden neuron layers
linear.output = T)
plot(nn)
predicted_values <- compute(nn, test[1:13])
str(predicted_values)
# undo scaled predictions
true_predictions <- predicted_values$net.result *
(max(data$medv)-min(data$medv)) + min(data$medv)
head(true_predictions)
test_r <- (test$medv) *
(max(data$medv)-min(data$medv)) + min(data$medv)
MSE_nn <- sum((test_r - true_predictions)^2) / nrow(test)
MSE_nn
error_df <- data.frame(test_r, true_predictions)
head(error_df)
ggplot(error_df,
aes(x = test_r,
y = true_predictions)) +
stat_smooth()
ggplot(error_df,
aes(x = test_r,
y = true_predictions)) +
geom_point +
stat_smooth()
ggplot(error_df,
aes(x = test_r,
y = true_predictions)) +
geom_point() +
stat_smooth()
knitr::opts_chunk$set(echo = TRUE)
# Set working directory
setwd("C:/Users/Oscar Ko/Desktop/100-Days-of-Data-Projects/9-NLP_WritingPrompts")
# Check current working directory
getwd()
# Lists files in current working directory
list.files()
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("WritingPrompts_data.csv")
head(data)
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("WritingPrompts_data.csv")
# Clear R's memory.
rm(list=ls())
# Set working directory
setwd("C:/Users/Oscar Ko/Desktop/100-Days-of-Data-Projects/9-NLP_WritingPrompts")
# Check current working directory
getwd()
# Lists files in current working directory
list.files()
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("WritingPrompts_data.csv")
###################################################
# CHECK THE DATA
head(data)
tail(data)
str(data)
summary(data)
# check number of rows and columns
nrow(data)
ncol(data)
# check column names
colnames(data)
# check for missing values
any(is.na(data))
# Amelia package for visualizing missing data
library(Amelia)
missmap(data,
main = "Missing Map",
col = c("red", "black"),
legend = T)
title_df <- select(data, title)
library(tidyverse)
title_df <- select(data, title)
missmap(title_df,
main = "Missing Map",
col = c("red", "black"),
legend = T)
head(title_df)
tail(title_df)
testing <- "[WP] Testing"
strsplit(testing, "]")
strsplit(testing, "]")[1]
strsplit(testing, "]")[1][1]
strsplit(testing, "]")[[1]]
what <- strsplit(testing, "]")
what
what[1]
what[1][1]
what[[1]
what[[1]]
what[[1]]
what[[1]]
what[[[1]]]
what[[1]][1]
raw_tag <- what[[1]][1][2:]
raw_tag
raw_tag <- what[[1]][1]
raw_tag
raw_tag[2:]
stringr::str_trunc(raw_tag, 2)
str_trunc(raw_tag, 2)
str_trunc(raw_tag, 1)
substring(raw_tag, 1)
substring(raw_tag, 2)
what[[1]][2]
split_title_tag <- strsplit(title_df$title, "]")
uncleaned_tags <- split_title_tag[[1]][1]
title_df$tag <- substring(split_title_tag, 2)
title_df$prompt <- split_title_tag[[1]][2]
head(title_df)
title_df$tag <- substring(uncleaned_tags, 2)
head(title_df)
all prompt tags and titles
title_df$tag <- substring(strsplit(title_df$title, "]")[[1]][1], 2)
title_df$prompt <- strsplit(title_df$title, "]")[[1]][2]
head(title_df)
# ----------------------------------------
# Seperate all prompt tags and titles
title_df$tag <- substring(strsplit(title_df$title, "]")[[1]][1], 2)
title_df$prompt <- strsplit(title_df$title, "]")[[1]][2]
head(title_df)
for (txt in title_df[2:5]$title) {
# split_txt = strsplit(title_df$title, "]")
#
# tag = substring(split_txt[[1]][1], 2)
# prompt = strsplit(split_txt, "]")[[1]][2]
print(txt)
}
for (txt in title_df$title[2:5]) {
# split_txt = strsplit(title_df$title, "]")
#
# tag = substring(split_txt[[1]][1], 2)
# prompt = strsplit(split_txt, "]")[[1]][2]
print(txt)
}
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(title_df$title, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = strsplit(split_txt, "]")[[1]][2]
append(tags, tag)
append(prompts, prompt)
}
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(title_df$title, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
append(tags, tag)
append(prompts, prompt)
}
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
prompt_df <- cbind(tags, prompts)
head(prompt_df)
tags
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(title_df$title, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
append(tags, tag)
append(prompts, prompt)
}
prompt_df <- cbind(tags, prompts)
head(prompt_df)
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
append(tags, tag)
append(prompts, prompt)
}
#
# prompt_df <- cbind(tags, prompts)
# head(prompt_df)
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
append(tags, tag)
append(prompts, prompt)
}
prompt_df <- cbind(tags, prompts)
head(prompt_df)
tags <- c()
prompts <- c()
for (txt in title_df$title[5:7]) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
print(tag, prompt)
# append(tags, tag)
# append(prompts, prompt)
}
print(tag)
for (txt in title_df$title[5:7]) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
print(tag)
# append(tags, tag)
# append(prompts, prompt)
}
for (txt in title_df$title[5:7]) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
print(prompt)
# append(tags, tag)
# append(prompts, prompt)
}
append(tags, tag)
tags <- c(tags, tag)
for (txt in title_df$title[5:7]) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
tags <- c(tags, tag)
prompts <- c(prompts, prompt)
}
tags <- c()
prompts <- c()
for (txt in title_df$title[5:7]) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
tags <- c(tags, tag)
prompts <- c(prompts, prompt)
}
# prompt_df <- cbind(tags, prompts)
# head(prompt_df)
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
s
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
tags <- c(tags, tag)
prompts <- c(prompts, prompt)
}
# prompt_df <- cbind(tags, prompts)
# head(prompt_df)
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
unique(title_df$tag)
title_df["man who sees ghosts checks himself into a mental institution" %in% title_df$title]
title_df[title_df$tag == error_tag]
error_tag <- " man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years. [WP"
title_df[title_df$tag == error_tag]
title_df[title_df$tag == error_tag]
title_df[title_df$tag == error_tags]
title_df[title_df$tag == error_tag]
title_df[title_df$tag == error_tag, ]
title_df[title_df$tag == error_tag, ]$title
title_df[title_df$tag == error_tag, ] <- c(the_title, the_tag, the_prompt)
the_title <- "A man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years."
the_tag <- "WP"
the_prompt <- "[WP] A man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years."
title_df[title_df$tag == error_tag, ] <- c(the_title, the_tag, the_prompt)
title_df <- title_df[title_df$tag != error_tag, ]
title_df <- rbind(title_df, c(the_title, the_tag, the_prompt))
tail(title_df)
###################################################
# NLP - WritingPrompts
# Clear R's memory.
rm(list=ls())
# Set working directory
setwd("C:/Users/Oscar Ko/Desktop/100-Days-of-Data-Projects/9-NLP_WritingPrompts")
# Check current working directory
getwd()
# Lists files in current working directory
list.files()
###################################################
# IMPORT DATA
# Faster way to import CSV with "vroom" package
library(vroom)
data <- vroom("WritingPrompts_data.csv")
###################################################
# CHECK THE DATA
head(data)
tail(data)
str(data)
summary(data)
# check number of rows and columns
nrow(data)
ncol(data)
# check column names
colnames(data)
# check for missing values
any(is.na(data))
# Amelia package for visualizing missing data
library(Amelia)
missmap(data,
main = "Missing Map",
col = c("red", "black"),
legend = T)
# -----------------------------------------
# Remove all columns except Title
library(tidyverse)
title_df <- select(data, title)
missmap(title_df,
main = "Missing Map",
col = c("red", "black"),
legend = T)
head(title_df)
tail
# ----------------------------------------
# Seperate all prompt tags and titles
tags <- c()
prompts <- c()
for (txt in title_df$title) {
split_txt = strsplit(txt, "]")
tag = substring(split_txt[[1]][1], 2)
prompt = split_txt[[1]][2]
tags <- c(tags, tag)
prompts <- c(prompts, prompt)
}
# prompt_df <- cbind(tags, prompts)
# head(prompt_df)
title_df$tag <- tags
title_df$prompt <- prompts
head(title_df)
unique(title_df$tag)
# -----------------------------------
# Clean the data
error_tag <- " man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years. [WP"
title_df[title_df$tag == error_tag, ]$title
the_title <- "[WP] A man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years."
the_tag <- "WP"
the_prompt <- "A man who sees ghosts checks himself into a mental institution, oblivious to the fact that the facility has been closed for almost thirty years."
title_df <- title_df[title_df$tag != error_tag, ]
title_df <- rbind(title_df, c(the_title, the_tag, the_prompt))
tail(title_df)
unique(title_df$tag)
unique(title_df$tag)
title_df <- title_df[title_df$tag %in% c("WP", "Wp", " WP ")]
title_df <- title_df[title_df$tag %in% c("WP", "Wp", " WP "), ]
unique(title_df$tag)
nrows(title_df)
nrow(title_df)
prompt_df <- select(title_df, prompts)
prompt_df <- select(title_df, prompt)
head(prompt_df)
tail(prompt_df)
